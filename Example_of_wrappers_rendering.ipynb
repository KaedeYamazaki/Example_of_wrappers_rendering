{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUJVeyCKQ-Vk"
      },
      "source": [
        "# **Example of wrappers.rendering**\n",
        "ソースコードは以下から参照されたい  \n",
        "[Source code for gymnasium.wrappers.rendering](https://gymnasium.farama.org/main/_modules/gymnasium/wrappers/rendering/#HumanRendering)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0huLvrwXwP7",
        "outputId": "7598b41b-b9a1-4ea5-9966-7b5ee05ab8ac"
      },
      "outputs": [],
      "source": [
        "if str(get_ipython()).startswith('<google.colab.'):\n",
        "    !pip install gymnasium"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwbvK-cFTmSq"
      },
      "source": [
        "## <font color= \"#ff2200\">**RenderCollectionラッパーの使い方**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bw0OZJUTojT"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "from gymnasium.wrappers import RenderCollection\n",
        "\n",
        "# 環境を作成し、RenderCollectionラッパーを適用\n",
        "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
        "env = RenderCollection(env)\n",
        "\n",
        "# 環境をリセット\n",
        "observation, info = env.reset(seed=42)\n",
        "\n",
        "# 200ステップ実行し、フレームを収集\n",
        "frames = []\n",
        "for _ in range(200):\n",
        "    action = env.action_space.sample()\n",
        "    observation, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "    if terminated or truncated:\n",
        "        break\n",
        "\n",
        "# 収集したフレームを取得\n",
        "frames = env.render()\n",
        "\n",
        "# フレーム数を出力\n",
        "print(f\"Collected {len(frames)} frames.\")\n",
        "\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uctXr-C7TqVJ"
      },
      "source": [
        "### **使い方**\n",
        "\n",
        "RenderCollectionラッパーは、環境のレンダリングされたフレームをリストに収集するためのものです。以下のように適用します。\n",
        "\n",
        "```python\n",
        "import gymnasium as gym\n",
        "from gymnasium.wrappers import RenderCollection\n",
        "\n",
        "env = gym.make(\"env_id\", render_mode=\"rgb_array\")\n",
        "env = RenderCollection(env)\n",
        "```\n",
        "\n",
        "レンダリングされたフレームは `env.render()` を呼び出すことで取得できます。さらに、以下のパラメータを指定できます。\n",
        "\n",
        "- `pop_frames` (デフォルト: True) - `render()`が呼び出された後にフレームリストを空にするかどうか\n",
        "- `reset_clean` (デフォルト: True) - `reset()`が呼び出された時にフレームリストを空にするかどうか\n",
        "\n",
        "\n",
        "\n",
        "上記のコードでは、CartPole-v1環境を作成し、RenderCollectionラッパーを適用しています。その後、200ステップ実行し、レンダリングされたフレームを収集しています。\n",
        "\n",
        "最後に `env.render()` を呼び出すと、収集したフレームのリストが返されます。デフォルトでは、この呼び出し後にフレームリストは空になります(`pop_frames=True`)。\n",
        "\n",
        "出力例:\n",
        "\n",
        "```\n",
        "Collected 200 frames.\n",
        "```\n",
        "\n",
        "収集したフレームは、後で動画に変換したり、フレーム単位での処理に使用できます。RenderCollectionは、レンダリングされた環境の経過を記録しておく際に便利です。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsPOoG7qQf1y"
      },
      "source": [
        "## <font color= \"#00ff00\">**RecordVideoラッパーの使い方**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qe-E9fsnI-U6",
        "outputId": "57cb594e-96c0-47c6-81ea-b59c293b052c"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gymnasium as gym\n",
        "from gymnasium.wrappers import RecordVideo\n",
        "\n",
        "# 動画を保存するフォルダを作成\n",
        "os.makedirs(\"videos\", exist_ok=True)\n",
        "\n",
        "# 環境を作成し、RecordVideoラッパーを適用\n",
        "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
        "trigger = lambda episode_id: episode_id % 10 == 0  # 10エピソードごとに録画\n",
        "env = RecordVideo(env, video_folder=\"videos/\", episode_trigger=trigger)\n",
        "\n",
        "# 100エピソード実行\n",
        "for episode in range(100):\n",
        "    observation, info = env.reset()\n",
        "    done = False\n",
        "    while not done:\n",
        "        action = env.action_space.sample()\n",
        "        observation, reward, terminated, truncated, info = env.step(action)\n",
        "        done = terminated or truncated\n",
        "\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeAKBZD2QPpO"
      },
      "source": [
        "### **使い方**\n",
        "\n",
        "RecordVideoラッパーは、環境のエピソードの動画を録画するためのものです。以下のようにして適用します。\n",
        "\n",
        "```python\n",
        "import gymnasium as gym\n",
        "from gymnasium.wrappers import RecordVideo\n",
        "\n",
        "env = gym.make(\"env_id\", render_mode=\"rgb_array\")\n",
        "env = RecordVideo(env, \n",
        "                  video_folder=\"videos/\", \n",
        "                  episode_trigger=lambda x: x % 10 == 0, \n",
        "                  step_trigger=None,\n",
        "                  video_length=0)\n",
        "```\n",
        "\n",
        "引数の説明:\n",
        "\n",
        "- `video_folder`: 動画を保存するフォルダパス\n",
        "- `episode_trigger`: エピソードを録画するかどうかを判断する関数\n",
        "- `step_trigger`: ステップを録画するかどうかを判断する関数\n",
        "- `video_length`: 動画の長さ(フレーム数)。0の場合はエピソード全体を録画\n",
        "\n",
        "`episode_trigger`と`step_trigger`はどちらか一方を指定する必要があります。どちらも指定しない場合は、特定のエピソードで自動的に録画が開始されます。\n",
        "\n",
        "\n",
        "上記のコードでは、CartPole-v1環境を作成し、RecordVideoラッパーを適用しています。`episode_trigger`として、10エピソードごとに録画を開始する関数を与えています。\n",
        "\n",
        "100エピソード実行した後、動画ファイルが `videos/` フォルダに保存されます。ファイル名は `rl-video-episode-{episode_id}.mp4` という形式になります。\n",
        "\n",
        "録画されたエピソードを確認するには、作成された動画ファイルを再生してみてください。\n",
        "\n",
        "RecordVideoラッパーは、エージェントの学習過程を可視化したり、特定のエピソードの振る舞いを記録したりするのに便利です。`episode_trigger`と`step_trigger`を適切に設定することで、必要な部分だけを選択的に録画できます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwZDcPLxUORo"
      },
      "source": [
        "## <font color= \"#0055ff\">**HumanRenderingクラスの使い方**</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQUc2TGTP8aG"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "\n",
        "# 環境作成時にHumanRenderingラッパーを適用\n",
        "env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
        "\n",
        "# 環境をリセット\n",
        "observation, info = env.reset(seed=42)\n",
        "\n",
        "# 50ステップ実行しながら、レンダリングを行う\n",
        "for _ in range(1000):\n",
        "    action = env.action_space.sample() # ランダムなアクションを選択\n",
        "    observation, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "    if terminated or truncated:\n",
        "        observation, info = env.reset()\n",
        "\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AL56NuNYR9W7"
      },
      "source": [
        "### **使い方**\n",
        "\n",
        "HumanRenderingラッパーは、環境の\"rgb_array\"レンダリングモードをウィンドウに表示するためのものです。以下の2つの方法でラッパーを適用できます。\n",
        "\n",
        "1. **環境ラッパー適用後**\n",
        "\n",
        "```python\n",
        "import gymnasium as gym\n",
        "from gymnasium.wrappers import HumanRendering\n",
        "\n",
        "env = gym.make(\"env_id\", render_mode=\"rgb_array\")\n",
        "env = HumanRendering(env)\n",
        "```\n",
        "\n",
        "2. **環境作成時**\n",
        "\n",
        "```python\n",
        "import gymnasium as gym\n",
        "\n",
        "env = gym.make(\"env_id\", render_mode=\"human\")\n",
        "```\n",
        "\n",
        "この方法では、環境が\"human\"レンダリングモードをネイティブにサポートしていない場合にのみ、HumanRenderingラッパーが自動的に適用されます。\n",
        "\n",
        "上記のコードを実行すると、LunarLanderの画面がウィンドウに表示され、環境が50ステップ進行するたびにフレームがレンダリングされます。\n",
        "\n",
        "環境がリセットされるたびに、新しいエピソードが始まり、ウィンドウにレンダリングされた最初のフレームが表示されます。\n",
        "\n",
        "HumanRenderingラッパーは、人間が環境を視覚化したり、動作を確認したりするのに便利です。ただし、レンダリングの [overhead](https://hldc.co.jp/blog/2022/12/15/11611/) が高いため、実際の強化学習トレーニングなどでは使用しないことをお勧めします。"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
